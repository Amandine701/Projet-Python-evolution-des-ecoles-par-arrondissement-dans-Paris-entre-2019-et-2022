import pandas as pd
import statsmodels.api as sm

# régression des effectifs par année et arrondissement sur une constante, certaines tranches d'âges (en âge d'avoir des enfants), et des effets fixes par arrondissement. 
# Etape 1 : on sélectionne les données nécessaires au sein de trois dataframes nb_eleve_arrondissement_annee, pop_all_years (extrait de la base logement), proportion_30_40_all_years (extrait de la base de recensement sur l'âge)
# Etape 2 : on crée un dataframe avec les ratios
# Etape 3 : on réalise la régression


#-------------------------------Etape 1-------------------------------------------------------------------
#------------------------------Création du dataframe nb_eleve_arrondissement_annee------------------------

# Extraction des données sur les effectifs pour les années 2019, 2020 et 2021 
# On extrait le dataframe nb_eleve_arrondissement_annee en reprenant le code du fichier stats_descr_effectif (lignes 19 à 33)

#--------------------------Création du dataframe pop_all_years (base de données logement)---------------------------------------------

# Extraction des données dans les dataframes pop_2019, pop_2020 et pop_2021 pour ne conserver que les arrondissements et la proportion de T3 et création du dataframe pop_all_years

nb_eleve_arrondissement_annee_reg= nb_eleve_arrondissement_annee

# En 2019
# On convertit la colonne ARM et NBPI en type numérique
pop_2019['ARM'] = pd.to_numeric(pop_2019['ARM'], errors='coerce')
pop_2019['NBPI'] = pd.to_numeric(pop_2019['NBPI'], errors='coerce')

# On filtre pour les arrondissements parisiens (ARM entre 75101 et 75120)
paris_data_2019_reg = pop_2019[pop_2019['ARM'].between(75101, 75120)].copy()

#  On calcule la proportion de T3
paris_data_2019_reg.loc[:, 'is_T3'] = paris_data_2019_reg['NBPI'] >= 3

# Création de la colonne 'is_bac+5' en fonction de DIPLM
paris_data_2019_reg.loc[:, 'is_bac+5'] = paris_data_2019_reg['DIPLM'].isin(['18', '19'])


# Affichage des premières lignes pour vérifier
print(paris_data_2019_reg[['ARM', 'is_T3', 'is_bac+5']].head())

pop_2019_reg = (
    paris_data_2019_reg.groupby('ARM')[['is_T3', 'is_bac+5']]  # Ajout des doubles crochets pour spécifier les colonnes
    .mean()
    .reset_index()
    .rename(columns={'is_T3': 'Proportion_3_pieces_ou_plus_2019', 'is_bac+5': 'Proportion_bac+5_2019'})
)

print(pop_2019_reg)

# En 2021
# On convertit la colonne ARM et NBPI en type numérique
pop_2021['ARM'] = pd.to_numeric(pop_2021['ARM'], errors='coerce')
pop_2021['NBPI'] = pd.to_numeric(pop_2021['NBPI'], errors='coerce')

# On filtre pour les arrondissements parisiens (ARM entre 75101 et 75120)
paris_data_2021_reg = pop_2021[pop_2021['ARM'].between(75101, 75120)].copy()

# Étape 2 : On calcule la proportion de T3
paris_data_2021_reg.loc[:, 'is_T3'] = paris_data_2021_reg['NBPI'] >= 3

# Création de la colonne 'is_bac+5' en fonction de DIPLM
paris_data_2021_reg.loc[:, 'is_bac+5'] = paris_data_2021_reg['DIPLM'].isin(['18', '19'])

# Affichage des premières lignes pour vérifier
print(paris_data_2021_reg[['ARM', 'is_T3', 'is_bac+5']].head())

pop_2021_reg = (
    paris_data_2021_reg.groupby('ARM')[['is_T3', 'is_bac+5']]  # Ajout des doubles crochets pour spécifier les colonnes
    .mean()
    .reset_index()
    .rename(columns={'is_T3': 'Proportion_3_pieces_ou_plus_2021', 'is_bac+5': 'Proportion_bac+5_2021'})
)

print(pop_2021_reg)

# On fusionne les dataframes
pop_logement_reg = pd.merge(
    pop_2019_reg,
    pop_2021_reg,
    on='ARM',
    how='inner',  # ou 'outer', 'left', 'right' selon vos besoins
    left_index=False
)

# On affiche le résultat
print(pop_logement_reg)

#---------------------------------Création du dataframe proportion_30_40_all_years (base de données recensement détaillant l'âge)----------------------------------

# On extrait la proportion d'adultes âgés entre 30 et 40 pour chaque arrondissement


# On filtre les données pour Paris (codes INSEE) et ne conserver que les variables d'intérêt
df_paris_ages_2019_reg = df_ages_2019[df_ages_2019['CODGEO'].isin(codes_insee_paris)][['CODGEO', 'AGED100', 'SEXE', 'NB']]

# On sélectionne les individus âgés de 30 à 40 ans
age_30_40_2019_reg = df_paris_ages_2019_reg[
    (df_paris_ages_2019_reg['AGED100'] >= 30) & (df_paris_ages_2019_reg['AGED100'] <= 40)
]

# On calcule l'effectif total de la population pour chaque arrondissement et on transforme en DataFrame
total_population_per_arrondissement_2019_reg = (
    df_paris_ages_2019_reg.groupby('CODGEO', as_index=False)
    .agg(Population_totale_2019=('NB', 'sum'))
)

# On calcule l'effectif des personnes âgées de 30 à 40 ans pour chaque arrondissement et on transforme en DataFrame
population_30_40_per_arrondissement_2019_reg = (
    age_30_40_2019_reg.groupby('CODGEO', as_index=False)
    .agg(Population_30_40_Ans_2019=('NB', 'sum'))
)

# On fusionne les deux DataFrames pour obtenir un tableau final avec les deux colonnes
df_population_paris_2019 = pd.merge(
    total_population_per_arrondissement_2019_reg,
    population_30_40_per_arrondissement_2019_reg,
    on='CODGEO',
    how='left'
)

# En 2021
# On filtre les données pour Paris (codes INSEE) et ne conserver que les variables d'intérêt
df_paris_ages_2021_reg = df_ages_2021[df_ages_2021['CODGEO'].isin(codes_insee_paris)][['CODGEO', 'AGED100', 'SEXE', 'NB']]

# On sélectionne les individus âgés de 30 à 40 ans
age_30_40_2021_reg = df_paris_ages_2021_reg[
    (df_paris_ages_2021_reg['AGED100'] >= 30) & (df_paris_ages_2021_reg['AGED100'] <= 40)
]

# On calcule l'effectif total de la population pour chaque arrondissement et on transforme en DataFrame
total_population_per_arrondissement_2021_reg = (
    df_paris_ages_2021_reg.groupby('CODGEO', as_index=False)
    .agg(Population_totale_2021=('NB', 'sum'))
)

# On calcule l'effectif des personnes âgées de 30 à 40 ans pour chaque arrondissement et on transforme en DataFrame
population_30_40_per_arrondissement_2021_reg = (
    age_30_40_2021_reg.groupby('CODGEO', as_index=False)
    .agg(Population_30_40_Ans_2021=('NB', 'sum'))
)

# On fusionne les deux DataFrames pour obtenir un tableau final avec les deux colonnes
df_population_paris_2021 = pd.merge(
    total_population_per_arrondissement_2021_reg,
    population_30_40_per_arrondissement_2021_reg,
    on='CODGEO',
    how='inner',
    left_index=False
)

# On fusionne les dataframes
population_paris_reg = pd.merge(
    df_population_paris_2019,
    df_population_paris_2021,
    on='CODGEO',
    how='inner'  # ou 'outer', 'left', 'right' selon vos besoins
)

# On affiche le résultat
print(population_paris_reg)


#-----------------------------Etape 2 on crée un dataframe avec les ratios-----------------------------------------------------------------------------
# On harmonise les données
nb_eleve_arrondissement_annee_reg['code_postal'] = nb_eleve_arrondissement_annee_reg['code_postal'] + 100
nb_eleve_arrondissement_annee_reg = nb_eleve_arrondissement_annee.rename(columns={'code_postal': 'CODGEO'})
pop_logement_reg= pop_logement_reg.rename(columns={'ARM': 'CODGEO'})


# On filtre les données pour 2019 et 2021 dans nb_eleve_arrondissement_annee
nb_eleves_2019_reg = nb_eleve_arrondissement_annee_reg[nb_eleve_arrondissement_annee['rentree_scolaire'] == 2019][['CODGEO', 'nombre_total_eleves']]
nb_eleves_2021_reg = nb_eleve_arrondissement_annee_reg[nb_eleve_arrondissement_annee['rentree_scolaire'] == 2021][['CODGEO', 'nombre_total_eleves']]

# On renomme les colonnes pour éviter les conflits
nb_eleves_2019_reg.rename(columns={'nombre_total_eleves': 'eleves_2019'}, inplace=True)
nb_eleves_2021_reg.rename(columns={'nombre_total_eleves': 'eleves_2021'}, inplace=True)

# On fusionne les données de 2019 et 2021 sur 'CODGEO'
eleves_ratio_reg = pd.merge(nb_eleves_2019_reg, nb_eleves_2021_reg, on='CODGEO')
eleves_ratio_reg['ratio_eleves'] = eleves_ratio_reg['eleves_2021'] / eleves_ratio_reg['eleves_2019']

# On calcule les ratios (effectifs 2021/effectifs 2019) pour 'Population_totale_2019' et 'Population_totale_2019'
population_paris_reg['ratio_population_totale'] = population_paris_reg['Population_totale_2021'] / population_paris_reg['Population_totale_2019']
population_paris_reg['ratio_population_30_40_Ans'] = population_paris_reg['Population_30_40_Ans_2021'] / population_paris_reg['Population_30_40_Ans_2019']

# On calcule les ratios (effectifs 2021/effectifs 2019) pour 'Proportion_3_pieces_ou_plus' et 'Proportion_bac+5'
pop_logement_reg['ratio_proportion_3_pieces_ou_plus'] =pop_logement_reg['Proportion_3_pieces_ou_plus_2021'] / pop_logement_reg['Proportion_3_pieces_ou_plus_2019']
pop_logement_reg['ratio_proportion_bac+5'] = pop_logement_reg['Proportion_bac+5_2021'] / pop_logement_reg['Proportion_bac+5_2019']

# Fusion de final_ratios_reg avec pop_logement_reg
final_ratios_reg = pd.merge(
    eleves_ratio_reg[['CODGEO', 'ratio_eleves']],
    pop_logement_reg[['CODGEO', 'ratio_proportion_3_pieces_ou_plus', 'ratio_proportion_bac+5']],
    on='CODGEO'
)

# Fusion de final_ratios_reg avec population_paris_reg
final_ratios_reg = pd.merge(
    final_ratios_reg[['CODGEO', 'ratio_eleves', 'ratio_proportion_3_pieces_ou_plus', 'ratio_proportion_bac+5']],
    population_paris_reg[['CODGEO', 'ratio_population_totale', 'ratio_population_30_40_Ans']],
    on='CODGEO'
)

# Affichage du DataFrame final fusionné
print(final_ratios_reg[['CODGEO', 'ratio_eleves', 'ratio_proportion_3_pieces_ou_plus', 'ratio_proportion_bac+5','ratio_population_totale', 'ratio_population_30_40_Ans']].head())
#--------------------------Etape 4 : on réalise la régression--------------------------------------

# On réalise la régression 
# On supprime les lignes avec des valeurs manquantes pour les variables explicatives uniquement
final_ratios_reg_clean = final_ratios_reg.dropna(
    subset=['CODGEO', 'ratio_eleves', 'ratio_proportion_3_pieces_ou_plus', 'ratio_proportion_bac+5','ratio_population_totale', 'ratio_population_30_40_Ans']
)

# Création des indicatrices pour CODGEO (arrondissements)
indicatrices_codgeo = pd.get_dummies(final_ratios_reg_clean['CODGEO'], prefix='arrondissement').astype(int)

# On supprime l'indicatrice du 20ᵉ arrondissement 
indicatrices_codgeo = indicatrices_codgeo.drop(columns=['arrondissement_75120'], errors='ignore')

# On définit les variables explicatives (on exclut CODGEO et ratio_eleves)
X_ratio = pd.concat([
    final_ratios_reg_clean[['ratio_proportion_3_pieces_ou_plus', 'ratio_proportion_bac+5','ratio_population_totale', 'ratio_population_30_40_Ans']],
    indicatrices_codgeo,
], axis=1)


# On ajoute une constante
X_ratio = sm.add_constant(X_ratio)

# Variable dépendante (nombre_total_eleves)
y_ratio = final_ratios_reg_clean['ratio_eleves']

# Modèle de régression linéaire
model_avec_ratios = sm.OLS(y_ratio, X_ratio)
results = model_avec_ratios.fit()

# Résumé des résultats
print(results.summary())

#--------------------------Etape 5 : on réalise une régression Lasso--------------------------------------

from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import pandas as pd

# On réalise la régression
# On supprime les lignes avec des valeurs manquantes pour les variables explicatives uniquement
final_ratios_reg_clean = final_ratios_reg.dropna(
    subset=['CODGEO', 'ratio_eleves', 'ratio_proportion_3_pieces_ou_plus', 'ratio_proportion_bac+5','ratio_population_totale', 'ratio_population_30_40_Ans']
)

# Création des indicatrices pour CODGEO (arrondissements)
indicatrices_codgeo = pd.get_dummies(final_ratios_reg_clean['CODGEO'], prefix='arrondissement').astype(int)

# On supprime l'indicatrice du 20ᵉ arrondissement 
indicatrices_codgeo = indicatrices_codgeo.drop(columns=['arrondissement_75120'], errors='ignore')

# On définit les variables explicatives (on exclut CODGEO et ratio_eleves)
X_ratio = pd.concat([
    final_ratios_reg_clean[['ratio_proportion_3_pieces_ou_plus', 'ratio_proportion_bac+5','ratio_population_totale', 'ratio_population_30_40_Ans']],
    indicatrices_codgeo,
], axis=1)

# Variable dépendante (nombre_total_eleves)
y_ratio = final_ratios_reg_clean['ratio_eleves']

# Normalisation des variables explicatives
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_ratio)

# Séparation en jeu d'entraînement et test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_ratio, test_size=0.2, random_state=42)

# Initialisation du modèle Lasso
lasso_model = Lasso(alpha=0.1)  # Vous pouvez ajuster alpha pour la régularisation

# Entraînement du modèle
lasso_model.fit(X_train, y_train)

# Coefficients du modèle
print("Coefficients du modèle Lasso :", lasso_model.coef_)

# Intercept du modèle
print("Intercept du modèle Lasso :", lasso_model.intercept_)

# Prédictions sur le jeu de test
y_pred = lasso_model.predict(X_test)

# Calcul du score (R²)
score = lasso_model.score(X_test, y_test)
print("Score R² du modèle Lasso :", score)


#--------------------------------On effectue une régression Ridge-----------------------------------------
# Importer les bibliothèques nécessaires
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np

# Charger vos données (assurez-vous que vous avez X et y prêts)
# Par exemple, si vous avez un DataFrame `final_ratios_reg_clean`
X = final_ratios_reg_clean[['ratio_proportion_3_pieces_ou_plus', 
                            'ratio_proportion_bac+5', 
                            'ratio_population_totale', 
                            'ratio_population_30_40_Ans']]

# Ajouter les indicatrices de CODGEO
X = pd.concat([X, indicatrices_codgeo], axis=1)

# Normalisation des données
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Variable dépendante
y = final_ratios_reg_clean['ratio_eleves']

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Créer un modèle de régression Ridge avec une valeur alpha
alpha = 0.95  # Vous pouvez tester différentes valeurs d'alpha
ridge_model = Ridge(alpha=alpha)

# Entraîner le modèle
ridge_model.fit(X_train, y_train)

# Afficher les coefficients
print("Coefficients de la régression Ridge:", ridge_model.coef_)

# Faire des prédictions sur l'ensemble de test
y_pred = ridge_model.predict(X_test)

# Évaluer le modèle (par exemple, avec R²)
from sklearn.metrics import mean_squared_error, r2_score
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Erreur quadratique moyenne (MSE):", mse)
print("R²:", r2)